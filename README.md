# Transformer From Scratch
> ðŸš§ **Status:** In developmentment 

A Transformer model implementation from scratch using PyTorch.

## Setup

This project requires conda for managing PyTorch and NumPy dependencies. Other development tools are installed via pip.

### Installation

```bash
git clone https://github.com/henok3878/transformer-from-scratch.git
cd transformer-from-scratch

# CPU version
conda env create -f environment-cpu.yml
conda activate transformer-cpu

# GPU version (with CUDA)
conda env create -f environment-gpu.yml  
conda activate transformer-gpu
```

## Development

### Code Quality Tools

```bash
black src/ tests/     # Format code
isort src/ tests/     # Sort imports  
flake8 src/ tests/    # Lint code
mypy src/            # Type checking
```

### Testing

```bash
pytest                    # Run tests
pytest --cov=transformer # With coverage
```

## Project Structure

```
src/transformer/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ multi_head.py          # Multi-head attention
â”‚   â”œâ”€â”€ encoder_block.py       # Transformer encoder
â”‚   â”œâ”€â”€ decoder_block.py       # Transformer decoder
â”‚   â”œâ”€â”€ input_embedding.py     # Token embeddings
â”‚   â”œâ”€â”€ positional_encoding.py # Position embeddings
â”‚   â”œâ”€â”€ feed_forward.py        # Position wise feed forward network
â”‚   â””â”€â”€ layer_norm.py          # Layer normalization
â”œâ”€â”€ transformer.py             # Complete model
â””â”€â”€ train.py                   # Training script

tests/                         # Unit tests
```

## License

MIT
